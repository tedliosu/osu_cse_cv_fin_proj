{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a39e4f38-994f-4928-9dc3-9614ded1525e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ combined_split_updated.csv created with columns: ['filename', 'split']\n",
      "\n",
      "Split seed ended up used: 11304\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Path to main dataset directory (with 4 subfolders, one per class)\n",
    "dataset_dir = \"../imgs_with_good_background\"\n",
    "final_combined_split_csv_name = \"combined_split_updated.csv\"\n",
    "train_col_name = \"train\"\n",
    "test_col_name = \"test\"\n",
    "final_comb_split_csv_cols = [\"filename\", \"split\"]\n",
    "list_of_bact_blight_folder_names = [\"bkgd1\", \"bkgd2\", \"bkgd_none\"]\n",
    "\n",
    "image_paths = []\n",
    "labels = []\n",
    "list_of_training_only_filenames = [\"soybean_rust_90.JPG\",\n",
    "                                   \"bacterial_blight_233.jpg\",\n",
    "                                   \"bacterial_blight_127.jpg\",\n",
    "                                   \"healthy_34.jpg\",\n",
    "                                   \"frogeye_1063.jpg\",\n",
    "                                   \"bacterial_blight_60.jpg\"]\n",
    "img_file_exts_tuple = (\".jpg\", \".jpeg\", \".png\", \".bmp\", \".tif\", \".tiff\")\n",
    "test_size_ratio = 0.3\n",
    "\n",
    "# Collect image paths and labels from each subfolder\n",
    "for class_name in os.listdir(dataset_dir):\n",
    "    class_path = os.path.join(dataset_dir, class_name)\n",
    "    if os.path.isdir(class_path):\n",
    "        for img_file in os.listdir(class_path):\n",
    "            if img_file.lower().endswith(img_file_exts_tuple):\n",
    "                image_paths.append(img_file)\n",
    "                labels.append(class_name)\n",
    "            elif any([img_file == dir_name \\\n",
    "                          for dir_name in list_of_bact_blight_folder_names]):\n",
    "                for sub_img_file in os.listdir(os.path.join(class_path, img_file)):\n",
    "                    if sub_img_file.lower().endswith(img_file_exts_tuple):\n",
    "                        image_paths.append(sub_img_file)\n",
    "                        labels.append(class_name)\n",
    "\n",
    "training_specific_in_test_paths = True\n",
    "random_state = 11293\n",
    "\n",
    "def do_test_paths_contain_training_points(test_paths):\n",
    "    for path_to_be_checked in test_paths:\n",
    "        if any([path_to_be_checked == train_only_filename \\\n",
    "                    for train_only_filename in list_of_training_only_filenames]):\n",
    "            return True\n",
    "\n",
    "while training_specific_in_test_paths:\n",
    "\n",
    "    # Perform stratified split\n",
    "    train_paths, test_paths, _, _ = train_test_split(\n",
    "        image_paths,\n",
    "        labels,\n",
    "        test_size=test_size_ratio,\n",
    "        stratify=labels,\n",
    "        random_state=random_state\n",
    "    )\n",
    "\n",
    "    if do_test_paths_contain_training_points(test_paths):\n",
    "        random_state += 1\n",
    "    else:\n",
    "        training_specific_in_test_paths = False\n",
    "\n",
    "# Build DataFrame with only filename and split label\n",
    "combined_data = []\n",
    "\n",
    "for path in train_paths:\n",
    "    filename = os.path.basename(path)\n",
    "    combined_data.append([filename, train_col_name])\n",
    "\n",
    "for path in test_paths:\n",
    "    filename = os.path.basename(path)\n",
    "    combined_data.append([filename, test_col_name])\n",
    "\n",
    "# Create and save CSV\n",
    "combined_df = pd.DataFrame(combined_data, columns=final_comb_split_csv_cols)\n",
    "combined_df.to_csv(final_combined_split_csv_name, index=False)\n",
    "\n",
    "print(f\"✅ {final_combined_split_csv_name} created with columns: {final_comb_split_csv_cols}\")\n",
    "print(f\"\\nSplit seed ended up used: {random_state}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a09fd8f-5b3b-454a-890f-68e23f75c70c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images preprocessing successful!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "base_path = dataset_dir\n",
    "output_path = \"./rohit_preprocessed_images_round_one\"\n",
    "\n",
    "# HSV threshold values to isolate green leaf regions\n",
    "lower_green = np.array([25, 40, 40])\n",
    "upper_green = np.array([85, 255, 255])\n",
    "img_new_size = (256, 256)\n",
    "\n",
    "# Create output directory\n",
    "os.makedirs(output_path, exist_ok=True)\n",
    "\n",
    "# Preprocessing function\n",
    "def preprocess_image(img_path):\n",
    "    img = cv2.imread(img_path)\n",
    "    if img is None:\n",
    "        return None\n",
    "\n",
    "    # Resize image\n",
    "    img = cv2.resize(img, img_new_size)\n",
    "\n",
    "    # Convert to HSV\n",
    "    hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "\n",
    "    # Apply CLAHE on V channel to enhance contrast\n",
    "    clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
    "    hsv[:, :, 2] = clahe.apply(hsv[:, :, 2])\n",
    "\n",
    "    # Apply Gaussian Blur to reduce noise\n",
    "    hsv_blurred = cv2.GaussianBlur(hsv, (5, 5), 0)\n",
    "\n",
    "    # Create mask for green leaf area\n",
    "    mask = cv2.inRange(hsv_blurred, lower_green, upper_green)\n",
    "\n",
    "    # Apply the mask to the original image\n",
    "    masked = cv2.bitwise_and(img, img, mask=mask)\n",
    "\n",
    "    return masked\n",
    "\n",
    "# Loop through each class folder\n",
    "for label in os.listdir(base_path):\n",
    "    class_folder = os.path.join(base_path, label)\n",
    "    if not os.path.isdir(class_folder):\n",
    "        continue\n",
    "\n",
    "    # Create output subfolder\n",
    "    output_class_folder = os.path.join(output_path, label)\n",
    "    os.makedirs(output_class_folder, exist_ok=True)\n",
    "\n",
    "    # Process each image in the class folder\n",
    "    for filename in os.listdir(class_folder):\n",
    "              \n",
    "        if any([filename == dir_name \\\n",
    "                    for dir_name in list_of_bact_blight_folder_names]):\n",
    "            subdir_path = os.path.join(class_folder, filename)\n",
    "            for sub_filename in os.listdir(subdir_path):\n",
    "                img_path = os.path.join(subdir_path, sub_filename)\n",
    "                preprocessed = preprocess_image(img_path)\n",
    "                if preprocessed is not None:\n",
    "                    save_path = os.path.join(output_class_folder, sub_filename)\n",
    "                    cv2.imwrite(save_path, preprocessed)\n",
    "        else:\n",
    "            img_path = os.path.join(class_folder, filename)\n",
    "            preprocessed = preprocess_image(img_path)\n",
    "            if preprocessed is not None:\n",
    "                save_path = os.path.join(output_class_folder, filename)\n",
    "                cv2.imwrite(save_path, preprocessed)\n",
    "\n",
    "print(\"Images preprocessing successful!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bffe76bf-10f0-4ddb-9684-f6756ca9f025",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved color features to: rohit_color_features2.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Path to preprocessed images\n",
    "input_dir = output_path\n",
    "color_features_col_names = [\"filename\", \"mean_H\", \"std_H\", \"mean_S\", \"std_S\", \"class\"]\n",
    "color_features_filename = \"rohit_color_features2.csv\"\n",
    "features = []\n",
    "\n",
    "for label in os.listdir(input_dir):\n",
    "    class_dir = os.path.join(input_dir, label)\n",
    "    for file in os.listdir(class_dir):\n",
    "        path = os.path.join(class_dir, file)\n",
    "        img = cv2.imread(path)\n",
    "        hsv = cv2.cvtColor(img, cv2.COLOR_BGR2HSV)\n",
    "        h, s, _ = cv2.split(hsv)\n",
    "\n",
    "        mean_h = np.mean(h)\n",
    "        std_h = np.std(h)\n",
    "        mean_s = np.mean(s)\n",
    "        std_s = np.std(s)\n",
    "\n",
    "        features.append([file, mean_h, std_h, mean_s, std_s, label])\n",
    "\n",
    "df = pd.DataFrame(features, columns=color_features_col_names)\n",
    "df.to_csv(color_features_filename, index=False)\n",
    "print(f\"Saved color features to: {color_features_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "df97c075-a449-4052-a4ff-0b70ba04d6fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved lesion shape features to: rohit_lesion_shape_features2.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Paths\n",
    "input_dir = output_path\n",
    "output_csv = \"rohit_lesion_shape_features2.csv\"\n",
    "shape_features_col_names = [\"filename\", \"lesion_count\",\n",
    "                            \"mean_lesion_area\", \"mean_eccentricity\",\n",
    "                            \"mean_circularity\", \"infected_area_pct\",\n",
    "                            \"class\"]\n",
    "\n",
    "# Output structure\n",
    "features = []\n",
    "\n",
    "def compute_circularity(area, perimeter):\n",
    "    if perimeter == 0:\n",
    "        return 0\n",
    "    return (4 * np.pi * area) / (perimeter ** 2)\n",
    "\n",
    "def compute_eccentricity(contour):\n",
    "    if len(contour) < 5:\n",
    "        return 0\n",
    "    ellipse = cv2.fitEllipse(contour)\n",
    "    major_axis = max(ellipse[1])\n",
    "    minor_axis = min(ellipse[1])\n",
    "    if major_axis == 0:\n",
    "        return 0\n",
    "    return np.sqrt(1 - (minor_axis / major_axis) ** 2)\n",
    "\n",
    "# Process each image\n",
    "for label in os.listdir(input_dir):\n",
    "    class_path = os.path.join(input_dir, label)\n",
    "    if not os.path.isdir(class_path):\n",
    "        continue\n",
    "\n",
    "    for file in os.listdir(class_path):\n",
    "        path = os.path.join(class_path, file)\n",
    "        img = cv2.imread(path)\n",
    "\n",
    "        if img is None:\n",
    "            continue\n",
    "\n",
    "        gray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "        # Apply threshold to isolate lesions (tune if needed)\n",
    "        _, binary = cv2.threshold(gray, 25, 255, cv2.THRESH_BINARY_INV)\n",
    "\n",
    "        # Find contours (lesions)\n",
    "        contours, _ = cv2.findContours(binary, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\n",
    "\n",
    "        lesion_areas = []\n",
    "        eccentricities = []\n",
    "        circularities = []\n",
    "\n",
    "        for cnt in contours:\n",
    "            area = cv2.contourArea(cnt)\n",
    "            if area < 30:  # skip tiny noise\n",
    "                continue\n",
    "            perimeter = cv2.arcLength(cnt, True)\n",
    "\n",
    "            lesion_areas.append(area)\n",
    "            eccentricities.append(compute_eccentricity(cnt))\n",
    "            circularities.append(compute_circularity(area, perimeter))\n",
    "\n",
    "        # Total leaf area (used for % infected)\n",
    "        leaf_mask = cv2.inRange(img, (1, 1, 1), (255, 255, 255))\n",
    "        leaf_area = cv2.countNonZero(leaf_mask)\n",
    "\n",
    "        total_lesion_area = sum(lesion_areas)\n",
    "        infected_pct = (total_lesion_area / (leaf_area + total_lesion_area)) * 100 if (leaf_area + total_lesion_area) > 0 else 0\n",
    "\n",
    "        # Store aggregated stats\n",
    "        features.append([\n",
    "            file,\n",
    "            len(lesion_areas),                           # Lesion count\n",
    "            np.mean(lesion_areas) if lesion_areas else 0,\n",
    "            np.mean(eccentricities) if eccentricities else 0,\n",
    "            np.mean(circularities) if circularities else 0,\n",
    "            infected_pct,\n",
    "            label\n",
    "        ])\n",
    "\n",
    "# Save to CSV\n",
    "df = pd.DataFrame(features, columns=shape_features_col_names)\n",
    "df.to_csv(output_csv, index=False)\n",
    "print(f\"Saved lesion shape features to: {output_csv}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78d1485b-342d-48bb-ba66-d140f964f312",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged features saved to rohit_combined_features2.csv\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load CSVs\n",
    "color_df = pd.read_csv(color_features_filename)\n",
    "lesion_df = pd.read_csv(output_csv)\n",
    "combined_df_filename = \"rohit_combined_features2.csv\"\n",
    "\n",
    "# Merge on filename\n",
    "merged_df = pd.merge(color_df, lesion_df, on=[\"filename\", \"class\"])\n",
    "\n",
    "# Save combined dataset\n",
    "merged_df.to_csv(combined_df_filename, index=False)\n",
    "print(f\"Merged features saved to {combined_df_filename}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
